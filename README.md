# ğŸ¬ Proyecto Individual NÂº1: Sistema de RecomendaciÃ³n de PelÃ­culas

---

## ğŸ“Œ DescripciÃ³n
Este proyecto simula el entorno real de trabajo de un **Ingeniero MLOps**, permitiendo ganar experiencia prÃ¡ctica en el desarrollo de aplicaciones basadas en datos, desde la recolecciÃ³n y transformaciÃ³n de informaciÃ³n hasta el despliegue de un modelo de machine learning en producciÃ³n.

La API proporciona funcionalidades avanzadas, como la obtenciÃ³n de datos por fechas, consultas de votaciones y el cÃ¡lculo de similitud entre pelÃ­culas para generar recomendaciones. AdemÃ¡s, este proyecto fomenta la **adquisiciÃ³n de habilidades esenciales para el mundo laboral**, incluyendo el anÃ¡lisis de datos, el diseÃ±o de sistemas de recomendaciÃ³n y la implementaciÃ³n de soluciones escalables en la web.

Finalmente, el proyecto culmina con el despliegue de la aplicaciÃ³n en **Render** y la creaciÃ³n de un video demostrativo que valida el funcionamiento del sistema, permitiendo aplicar lo aprendido en un contexto realista y prepararse para el entorno profesional en ciencia de datos y MLOps.

---

## ğŸ“‚ Estructura del Proyecto

```plaintext
proyecto_recomendacion_peliculas/
â”œâ”€â”€ .vscode/                       # ConfiguraciÃ³n de VS Code (opcional)
â”œâ”€â”€ api/                           # ImplementaciÃ³n de la API
â”‚   â”œâ”€â”€ __pycache__/               # Archivos de cachÃ© de Python generados automÃ¡ticamente
â”‚   â””â”€â”€ main.py                    # Archivo principal para iniciar la API (FastAPI)
â”œâ”€â”€ datos/                         # Almacenamiento de los datasets
â”‚   â”œâ”€â”€ credits.csv                # Dataset original de crÃ©ditos de pelÃ­culas
â”‚   â”œâ”€â”€ credits_desanidado.csv     # Dataset de crÃ©ditos desanidado
â”‚   â”œâ”€â”€ data_peliculas.csv         # Dataset original de pelÃ­culas
â”‚   â”œâ”€â”€ data_peliculas_reducido.csv# VersiÃ³n reducida del dataset de pelÃ­culas
â”‚   â”œâ”€â”€ Diccionario de Datos - PIMLO.xlsx # Diccionario de datos para referencia
â”‚   â”œâ”€â”€ movies_dataset.csv         # Dataset original de pelÃ­culas
â”‚   â””â”€â”€ movies_dataset_desanidado.csv # Dataset de pelÃ­culas desanidado
â”œâ”€â”€ modelo/                        # Modelo de machine learning
â”‚   â”œâ”€â”€ modelo_recomendacion_pca.pkl # Modelo entrenado de recomendaciÃ³n basado en PCA
â”‚   â”œâ”€â”€ modelo.ipynb               # Notebook para el entrenamiento del modelo
â”‚   â”œâ”€â”€ pca_model.pkl              # Archivo guardado del modelo PCA
â”‚   â””â”€â”€ titulos.pkl                # Archivo de tÃ­tulos de pelÃ­culas para recomendaciones
â”œâ”€â”€ raiz/                          # Archivos de configuraciÃ³n de entorno
â”‚   â””â”€â”€ venv/                      # Entorno virtual para el proyecto
â”œâ”€â”€ scripts/                       # Scripts de procesamiento y anÃ¡lisis de datos
â”‚   â”œâ”€â”€ EDA.ipynb                  # AnÃ¡lisis Exploratorio de Datos (EDA)
â”‚   â”œâ”€â”€ ETL credits.ipynb          # Proceso ETL de crÃ©ditos
â”‚   â””â”€â”€ ETL movies_dataset.ipynb   # Proceso ETL del dataset de pelÃ­culas
â””â”€â”€ requirements.txt               # Dependencias necesarias para el proyecto

ğŸ“ DescripciÃ³n General

El sistema de recomendaciÃ³n de pelÃ­culas consta de las siguientes etapas principales:
1. ETL (ExtracciÃ³n, TransformaciÃ³n y Carga)
ğŸ“¥ 1.1 ExtracciÃ³n de Datos

    Se obtuvieron los datasets movies_dataset.csv y credits.csv del repositorio proporcionado por Henry.
    Se descargÃ³ el Diccionario de Datos para entender las columnas disponibles. 

ğŸ”„ 1.2 TransformaciÃ³n

    Se utilizÃ³ Visual Studio Code y se creÃ³ un entorno virtual para gestionar las dependencias.
    Se desarrollaron los notebooks ETL credits.ipynb y ETL movies_dataset.ipynb.
    Se desanidaron campos como belongs_to_collection y production_companies que estaban en formato de diccionario o lista.
    Transformaciones aplicadas:
        Valores nulos: Los campos revenue y budget con valores nulos se rellenaron con 0.
        Fechas faltantes: Las filas con valores nulos en release date se eliminaron.
        Formato de fecha: Se estandarizaron las fechas al formato AAAA-mm-dd.
        AÃ±o de estreno: Se creÃ³ la columna release_year extrayendo el aÃ±o de la fecha de estreno.
        Retorno de inversiÃ³n: Se creÃ³ la columna return calculando revenue / budget, asignando 0 cuando no habÃ­a datos disponibles.
        Columnas eliminadas: Se eliminaron las columnas video, imdb_id, adult, original_title, poster_path y homepage. 

ğŸ“¤ 1.3 Carga

    Tras la limpieza y transformaciÃ³n, se generaron grÃ¡ficos para visualizar y comprender mejor los datos. 

2. ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA)

    Se creÃ³ el notebook EDA.ipynb para realizar el anÃ¡lisis estadÃ­stico.
    Se identificaron y trataron valores faltantes y duplicados.
    Se unieron los datasets basados en el id de las pelÃ­culas.
    Se eliminaron columnas irrelevantes y se tradujeron los nombres de las columnas al espaÃ±ol.
    Se aplicÃ³ One-Hot Encoding a los gÃ©neros, creando columnas binarias para cada gÃ©nero.
    Se generaron grÃ¡ficos para identificar patrones y tendencias que puedan influir en el modelo de recomendaciÃ³n. 

3. ğŸš€ Desarrollo de la API

    Se desarrollÃ³ una API utilizando el framework FastAPI.
    Funcionalidades implementadas:
        Cantidad de filmaciones por mes : Permite obtener la cantidad de filmaciones registradas en un mes especÃ­fico.
        Cantidad de filmaciones por dÃ­a : Proporciona el nÃºmero de filmaciones registradas en un dÃ­a especÃ­fico.
        Score de una filmaciÃ³n : Devuelve el puntaje asociado a una pelÃ­cula especÃ­fica.
        Cantidad de votos de una filmaciÃ³n : Muestra la cantidad de votos recibidos por una pelÃ­cula.
        Obtener actor : Proporciona informaciÃ³n sobre un actor en particular.
        Obtener director : Proporciona informaciÃ³n sobre un director especÃ­fico. 

4. ğŸ§  ConstrucciÃ³n del Modelo de RecomendaciÃ³n

    Se utilizÃ³ el dataset data_peliculas_reducido.csv, reduciendo a 5000 pelÃ­culas mÃ¡s relevantes por cuestiones de rendimiento.
    Pasos realizados:
        SelecciÃ³n de caracterÃ­sticas relevantes : Se seleccionaron las variables mÃ¡s significativas y se manejaron los valores faltantes.
        ReducciÃ³n de dimensionalidad : Se aplicÃ³ PCA para reducir a un mÃ¡ximo de 30 componentes, simplificando los datos y manteniendo la mayor cantidad de informaciÃ³n posible.
        Modelo de Vecinos MÃ¡s Cercanos : Se utilizÃ³ Nearest Neighbors con similitud de coseno para encontrar pelÃ­culas similares.
        Entrenamiento y guardado del modelo : El modelo entrenado se guardÃ³ para su uso posterior sin necesidad de reentrenamiento. 

5. ğŸŒ Despliegue de la API

    La API se desplegÃ³ en la plataforma Render , haciÃ©ndola accesible para usuarios finales. 

6. âš™ï¸ Framework Utilizado

    Se empleÃ³ FastAPI para el desarrollo de la API, facilitando la construcciÃ³n de servicios web basados en Python de manera rÃ¡pida y sencilla. 

ğŸ“¦ Requisitos y Dependencias

Para ejecutar este proyecto, es necesario tener instaladas las siguientes dependencias:

annotated-types==0.7.0
anyio==4.6.2.post1
click==8.1.7
colorama==0.4.6
faiss-cpu==1.9.0
fastapi==0.115.4
h11==0.14.0
idna==3.10
joblib==1.4.2
numpy==2.1.3
packaging==24.1
pandas==2.2.3
pydantic==2.9.2
pydantic_core==2.23.4
python-dateutil==2.9.0.post0
pytz==2024.2
scikit-learn==1.5.2
scipy==1.14.1
six==1.16.0
sniffio==1.3.1
starlette==0.41.2
threadpoolctl==3.5.0
typing_extensions==4.12.2
tzdata==2024.2
uvicorn==0.32.0
#Link de render
https://proyecto-individual-n-1-sistema-de.onrender.com/docs#/default/recomendacion_recomendacion__titulo__get
